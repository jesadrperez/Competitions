{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Blight Violations\n",
    "\n",
    "_This project was completed as a part of the Applied Data Science with Python Specialization from Coursera._\n",
    "\n",
    "In this project, we will evaluate the performance and predictive power of a model that has been trained and tested on data collected from Blight Violation Notices (BVN), or Blight Tickets, that have been issued to property owners who have violated City of Detroit ordinances that govern how property owners must maintain the exterior of their property. Blight Tickets are issued by city inspectors, police officers, neighborhood city hall managers and other city officials who investigate complaints of blight and are managed by the Department of Administrative Hearings.\n",
    "\n",
    "The target variable is compliance, which is __True__ if the ticket was paid early, on time, or within one month of the hearing data, __False__ if the ticket was paid after the hearing date or not at all, and __Null__ if the violator was found not responsible. Compliance is not avaliable in the dataset so it must be calculated.\n",
    "\n",
    "The dataset for this project originates from the City of Detroit's Open Data Portal initiative and is updated daily. For this project the dataset spans tickets issued from March 2004 to March 2018. The dataset is avaliable at: https://data.detroitmi.gov/Property-Parcels/Blight-Violations/ti6p-wcg4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "Imports the raw data, calculates compliance for each ticket, removes features that cause data leakage, and seperates the data into two dataset based on when the violation occured. Violations issused before 2017 will be used to train and test the model, and tickets issued on and after 2017 will be used to validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "# To make the notebook's output stable across runs\n",
    "random_seed = 12062017\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_blight_raw(blight_path):\n",
    "    '''\n",
    "    Loads the raw blight_violations.csv\n",
    "    Returns a pandas dataframe.\n",
    "    '''\n",
    "    csv_path = os.path.join(blight_path, \"Blight_Violations.csv\")\n",
    "    blight_raw = pd.read_csv(csv_path, encoding='ISO-8859-1')\n",
    "    print(\"RAW Blight Violations dataset has {} observations with {} features each.\".format(*blight_raw.shape))\n",
    "    return blight_raw\n",
    "\n",
    "def pre_processing(blight_df):\n",
    "    ''' \n",
    "    Takes blight panda dataframe and makes column names more reabable, sets ticket_id as index, creates compliance (the \n",
    "    prediction variable), and creates compliance_details (explains why a tickets was labeled as complantent or non-complantent).\n",
    "    Returns a panda dataframe.\n",
    "    '''\n",
    "    # Makes column names more reabable\n",
    "    # Gets columns from dataframe\n",
    "    columns_names = pd.Series(blight_df.columns)\n",
    "    # Removes parentheses, removes right spaces\n",
    "    columns_names = columns_names.str.split('(').str[0].str.strip()\n",
    "    # Coverts column names to lowercase and replaces spaces with underscores\n",
    "    columns_names = columns_names.str.lower().str.replace(' ', '_')\n",
    "    blight_df.columns = columns_names\n",
    "    # Sets ticket_id as index\n",
    "    blight_df.set_index('ticket_id', inplace=True)\n",
    "    # Defines prediction variable compliance and helper variable compliance_detail\n",
    "    # The values of these variables are NOT correct\n",
    "    blight_df['compliance'] = 0\n",
    "    blight_df['compliance_detail'] = np.NaN    \n",
    "    return blight_df\n",
    "\n",
    "def clean_up(blight_df):\n",
    "    # Removes instances where 'ticket_issued_date' is not in (2000, 2017) \n",
    "    blight_df = blight_df[blight_df['violation_date'].str.contains('[0-9]{2}/[0-9]{2}/[20]{2}[0-9]{2}') == True]\n",
    "    # Converts 'ticket_issued_date' to datetime\n",
    "    blight_df.loc[:, 'violation_date'] = pd.to_datetime(blight_df['violation_date'])\n",
    "    # Converts 'payment_date' to datetime\n",
    "    blight_df.loc[:, 'payment_date'] = pd.to_datetime(blight_df['payment_date'].str.extract('([0-9]{2}/[0-9]{2}/20{1}[0-9]{2})')) \n",
    "    # Converts bad values in 'ticket_issued_time' to NaNs (Dataset error removed by publisher)\n",
    "    #blight_df.loc[blight_df['violation_date'] == '00000000000000.000', 'violation_date'] = np.nan\n",
    "    # Converts 'ticket_issued_time' to datetime.time\n",
    "    blight_df.loc[:, 'ticket_issued_time'] = pd.DatetimeIndex(blight_df['ticket_issued_time']).time\n",
    "    # Converts 'hearing_time' to datetime.time\n",
    "    blight_df.loc[:, 'hearing_time'] = pd.DatetimeIndex(blight_df['hearing_time']).time\n",
    "    # Remove \"$\" from 'judgement_amount'\n",
    "    blight_df.loc[:, 'judgment_amount'] = blight_df['judgment_amount'].str.strip('$')    \n",
    "    # Converts 'judgment_amount' to float    \n",
    "    blight_df.loc[:, 'judgment_amount'] = blight_df['judgment_amount'].astype(float)\n",
    "    # Removes \"$\" from 'payment_amount' and converts it to float\n",
    "    blight_df.loc[:, 'payment_amount'] = blight_df['payment_amount'].str.strip('$').astype(float)\n",
    "    # Removes \"$\" from 'fine_amount' and converts it to float\n",
    "    blight_df.loc[:, 'fine_amount'] = blight_df['fine_amount'].str.strip('$').astype(float)\n",
    "    # Removes \"$\" from 'admin_fee' and converts it to float\n",
    "    blight_df.loc[:, 'admin_fee'] = blight_df['admin_fee'].str.strip('$').astype(float)\n",
    "    # Removes \"$\" from 'state_fee' and converts it to float\n",
    "    blight_df.loc[:, 'state_fee'] = blight_df['state_fee'].str.strip('$').astype(float)\n",
    "    # Removes \"$\" from 'late_fee' and converts it to float\n",
    "    blight_df.loc[:, 'late_fee']   = blight_df['late_fee'].str.strip('$').astype(float)\n",
    "    # Removes \"$\" from 'discount_amount' and converts it to float\n",
    "    blight_df.loc[:, 'discount_amount'] = blight_df['discount_amount'].str.strip('$').astype(float)    \n",
    "    return blight_df\n",
    "\n",
    "def null_compliance(blight_df):\n",
    "    '''\n",
    "    Compliance = np.NaN\n",
    "    Tickets that cannot be classified as compliant or non-compliant because they were ruled as not responsible in disposition\n",
    "    or they are awaiting judgement.\n",
    "    Returns a pandas dataframe\n",
    "    '''\n",
    "    # Dispositions that are ruled as not responsible or are still pending\n",
    "    null_dispositions = ['Not responsible by Dismissal', 'Not responsible by City Dismissal', 'PENDING JUDGMENT', \n",
    "                 'Not responsible by Determination','SET-ASIDE (PENDING JUDGMENT)', 'PENDING', 'Responsible by Dismissal']\n",
    "    # Loops over dispositions and sets 'compliance' values to np.NaN\n",
    "    # Loops over dispositions and sets 'compliance_detail' values to 'Not Responsible/Pending Judgement'\n",
    "    for dispositions in null_dispositions:\n",
    "        blight_df.loc[blight_df['disposition'] == dispositions, 'compliance'] = np.NaN\n",
    "        blight_df.loc[blight_df['disposition'] == dispositions, 'compliance_detail'] = 'Not Responsible/Pending Judgement'\n",
    "    return blight_df\n",
    "\n",
    "def compliant(blight_df):\n",
    "    '''\n",
    "    Compliance = 1\n",
    "    Tickets that are classified as compliant because they had no fine, fine was waved, made a payment with hearing pending,\n",
    "    early payment (hearing not pending), payment on time, or payment within one month after hearing date.\n",
    "    Returns a pandas dataframe\n",
    "    '''\n",
    "    ## Compliant by no fine\n",
    "    # Fine Waived by Determintation\n",
    "    blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Determination', 'compliance'] = 1\n",
    "    blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Determination', 'compliance_detail'] = 'Compliant by no fine'\n",
    "    # Fine Waived by Admission\n",
    "    blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Admission', 'compliance'] = 1\n",
    "    blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Admission', 'compliance_detail'] = 'Compliant by no fine'\n",
    "    ## Compliant by Payment\n",
    "    # Payment with PENDING hearing\n",
    "    blight_df.loc[(\n",
    "        (blight_df['hearing_date'] == 'PENDING') &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance'] = 1\n",
    "    blight_df.loc[(\n",
    "        (blight_df['hearing_date'] == 'PENDING') &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Compliant by payment with PENDING hearing'\n",
    "    # Transforms values in 'hearing_date' and 'payment_date' to panda date types\n",
    "    dummy_hearing_date = blight_df['hearing_date'].copy()\n",
    "    blight_df.loc[blight_df['hearing_date'] == 'PENDING', 'hearing_date'] = np.nan\n",
    "    blight_df.loc[:, 'hearing_date'] = pd.to_datetime(blight_df['hearing_date'].str.extract('([0-9]{2}/[0-9]{2}/20{1}[0-9]{2})'))\n",
    "    # Early Payment, payment before hearing date\n",
    "    blight_df.loc[(\n",
    "        (blight_df['payment_date'] < blight_df['hearing_date']) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance'] = 1\n",
    "    blight_df.loc[(\n",
    "        (blight_df['payment_date'] < blight_df['hearing_date']) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Compliant by early payment'\n",
    "    # Payment on time, payment on hearing date\n",
    "    blight_df.loc[(\n",
    "        (blight_df['payment_date'] == blight_df['hearing_date']) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance'] = 1\n",
    "    blight_df.loc[(\n",
    "        (blight_df['payment_date'] == blight_df['hearing_date']) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Compliant by payment on time'\n",
    "    # Payment within one month after hearing date\n",
    "    blight_df.loc[(\n",
    "        ((blight_df['payment_date'] - blight_df['hearing_date'])/np.timedelta64(1, 'M') <= 1.0) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance'] = 1\n",
    "    blight_df.loc[(\n",
    "        ((blight_df['payment_date'] - blight_df['hearing_date'])/np.timedelta64(1, 'M') <= 1.0) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Compliant by payment within 1 Month'\n",
    "    # Sets 'hearing_date' to orginal state\n",
    "    blight_df.loc[:, 'hearing_date'] = dummy_hearing_date\n",
    "    return blight_df\n",
    "\n",
    "def non_compliant(blight_df):\n",
    "    '''\n",
    "    Compliance = 0\n",
    "    Tickets that are classified as non-compliant because they made no payment or a payment after one month (late payment).\n",
    "    Returns a pandas dataframe\n",
    "    '''\n",
    "    # Transforms values in 'hearing_date' to panda date types\n",
    "    dummy_hearing_date = blight_df['hearing_date'].copy()\n",
    "    blight_df.loc[blight_df['hearing_date'] == 'PENDING', 'hearing_date'] = np.nan\n",
    "    blight_df.loc[:, 'hearing_date'] = pd.to_datetime(blight_df['hearing_date'].str.extract('([0-9]{2}/[0-9]{2}/20{1}[0-9]{2})'))\n",
    "    # Non-compliant by late payment\n",
    "    blight_df.loc[(\n",
    "        ((blight_df['payment_date'] - blight_df['hearing_date'])/np.timedelta64(1, 'M') > 1.0) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Non-compliant by late payment more than 1 month'\n",
    "    # Non-compliant by no payment\n",
    "    blight_df.loc[blight_df['compliance_detail'].isnull(), 'compliance_detail'] = 'Non-compliant by no payment'\n",
    "    # Sets 'hearing_date' to orginal state\n",
    "    blight_df.loc[:, 'hearing_date'] = dummy_hearing_date\n",
    "    return blight_df\n",
    "\n",
    "def populate_compliance(blight_df):\n",
    "    '''\n",
    "    Populates compliance and compliance_details in blight_df with the correct values. \n",
    "    Returns a panda dataframe.\n",
    "    '''\n",
    "    blight_df = null_compliance(blight_df)\n",
    "    blight_df = compliant(blight_df)\n",
    "    blight_df = non_compliant(blight_df)  \n",
    "    return blight_df\n",
    "\n",
    "def remove_leakage(blight_df):\n",
    "    ''' \n",
    "    In blight_df removes variables to prevent data leakage and variables with mostly NaNs,\n",
    "    Returns a panda dataframe\n",
    "    '''\n",
    "    blight_df = blight_df[['agency_name', 'inspector_name', 'violator_name','violation_street_number', 'violation_street_name', \n",
    "                       'mailing_address_street_name', 'mailing_address_street_name', 'mailing_address_city', \n",
    "                       'mailing_address_state', 'mailing_address_zip_code', 'mailing_address_non-usa_code', \n",
    "                       'mailing_address_country', 'violation_date', 'hearing_date', 'hearing_time', 'violation_code', 'violation_description',\n",
    "                       'disposition', 'fine_amount', 'admin_fee', 'state_fee', 'late_fee', 'discount_amount', \n",
    "                       'judgment_amount', 'violation_latitude', 'violation_longitude', 'compliance']]  \n",
    "    return blight_df \n",
    "\n",
    "def process_blight(blight_path, pre_process):\n",
    "    '''\n",
    "    If pre_process is true - Loads the raw blight_violations.csv, cleans the data, computes compliance, removes features with \n",
    "    data leakage and saves this dataframe. If pre_process is False, then it loads the pre-processed data.\n",
    "    Returns a pandas dataframe.\n",
    "    '''\n",
    "    if pre_process == False:\n",
    "        blight_df = load_blight_raw(blight_path)\n",
    "        blight_df = pre_processing(blight_df)\n",
    "        blight_df = clean_up(blight_df)\n",
    "        blight_df = populate_compliance(blight_df)\n",
    "        blight_df = remove_leakage(blight_df)\n",
    "        save_blight_data(blight_path, blight_df)\n",
    "    else:\n",
    "        blight_df = load_blight(blight_path)\n",
    "    print(\"PROCESSED Blight Violations dataset has {} observations with {} features each.\".format(*blight_df.shape))        \n",
    "    return blight_df\n",
    "\n",
    "def save_blight_data(blight_path, blight_df):\n",
    "    '''\n",
    "    Saves the processed blight_df\n",
    "    Returns nothing.\n",
    "    '''\n",
    "    csv_path = os.path.join(blight_path, \"Blight_Violations_Processed.csv\")\n",
    "    blight_df.to_csv(csv_path)\n",
    "    \n",
    "def load_blight(blight_path):\n",
    "    '''\n",
    "    Loads the preprocessed blight_violations.csv\n",
    "    Returns a pandas dataframe.\n",
    "    '''\n",
    "    csv_path = os.path.join(blight_path, \"Blight_Violations_Processed.csv\")\n",
    "    blight_df = pd.read_csv(csv_path)\n",
    "    blight_df.set_index('ticket_id', inplace=True)\n",
    "    return blight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2910: DtypeWarning: Columns (8,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW Blight Violations dataset has 373848 observations with 40 features each.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:149: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSED Blight Violations dataset has 373844 observations with 27 features each.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 373844 entries, 47056 to 247933\n",
      "Data columns (total 27 columns):\n",
      "agency_name                     373844 non-null object\n",
      "inspector_name                  373844 non-null object\n",
      "violator_name                   373842 non-null object\n",
      "violation_street_number         373844 non-null int64\n",
      "violation_street_name           373779 non-null object\n",
      "mailing_address_street_name     373841 non-null object\n",
      "mailing_address_street_name     373841 non-null object\n",
      "mailing_address_city            372028 non-null object\n",
      "mailing_address_state           371565 non-null object\n",
      "mailing_address_zip_code        372025 non-null object\n",
      "mailing_address_non-usa_code    1819 non-null object\n",
      "mailing_address_country         1830 non-null object\n",
      "violation_date                  373844 non-null datetime64[ns]\n",
      "hearing_date                    373234 non-null object\n",
      "hearing_time                    373233 non-null object\n",
      "violation_code                  373843 non-null object\n",
      "violation_description           373843 non-null object\n",
      "disposition                     365161 non-null object\n",
      "fine_amount                     373842 non-null float64\n",
      "admin_fee                       373844 non-null float64\n",
      "state_fee                       373844 non-null float64\n",
      "late_fee                        373844 non-null float64\n",
      "discount_amount                 373844 non-null float64\n",
      "judgment_amount                 373844 non-null float64\n",
      "violation_latitude              373719 non-null float64\n",
      "violation_longitude             373719 non-null float64\n",
      "compliance                      251545 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(9), int64(1), object(16)\n",
      "memory usage: 89.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loads the raw blight data and pre-processes\n",
    "blight_df = process_blight(r\"C:\\Users\\Adrian\\Google Drive\\Datasets\\Blight-Violations\", False)\n",
    "#blight_df = process_blight(r\"C:\\Users\\aperez\\Google Drive\\Datasets\\Blight-Violations\", True)\n",
    "# Checks to make sure the data loaded properly\n",
    "blight_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets remove unrelevant fields and useless observations -\n",
    "* Observations where compliance is _NaNs_, these observations provide no use to me\n",
    "* Features that are too noisey or contain many _NaNs_: inspector_name, violator_name, violation_street_number, violation_street_name, mailing_address_street_name, mailing_address_street_name.1, violation_code, and violation_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 251545 entries, 47056 to 359077\n",
      "Data columns (total 18 columns):\n",
      "agency_name                251545 non-null object\n",
      "mailing_address_city       249910 non-null object\n",
      "mailing_address_state      249495 non-null object\n",
      "mailing_address_country    1646 non-null object\n",
      "violation_date             251545 non-null datetime64[ns]\n",
      "hearing_date               250935 non-null object\n",
      "hearing_time               250934 non-null object\n",
      "violation_description      251544 non-null object\n",
      "disposition                242862 non-null object\n",
      "fine_amount                251544 non-null float64\n",
      "admin_fee                  251545 non-null float64\n",
      "state_fee                  251545 non-null float64\n",
      "late_fee                   251545 non-null float64\n",
      "discount_amount            251545 non-null float64\n",
      "judgment_amount            251545 non-null float64\n",
      "violation_latitude         251451 non-null float64\n",
      "violation_longitude        251451 non-null float64\n",
      "compliance                 251545 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(9), object(8)\n",
      "memory usage: 36.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop observations where compliance is NaNs\n",
    "blight_df.dropna(axis=0, subset=['compliance'], inplace=True)\n",
    "# Drop useless features\n",
    "blight_df.drop(axis=1, columns=['inspector_name', 'violator_name', 'violation_street_number', 'violation_street_name',\n",
    "       'mailing_address_street_name', 'mailing_address_zip_code', 'mailing_address_non-usa_code',\n",
    "        'violation_code'], inplace=True)\n",
    "blight_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "\n",
    "Now, we will construct new features. These are:\n",
    "* detriot_resident - _True_ if 'mailing_address_city' is Detriot, _False_ otherwise\n",
    "* michigan_resident - _True_ if 'mailing_address_state' is Michigan, _False_ otherwise\n",
    "* us_resident - _True_ if 'mailing_address_state' is not null but _False_ if 'mailing_address_country' is not null, _False_ otherwise\n",
    "* violation_month = the numeric month (1-12) that violation occured on\n",
    "* days_difference = the number of days between when the violation occured and when the hearing date is\n",
    "* disposition_fine_waived = _True_ if  'disposition' is \"Responsible (Fine Waived) by Determination\" or \"Responsible (Fine Waived) by Admission\",  _False_ otherwise\n",
    "* disposition_default = _True_ if  'disposition' is \"Responsible by Default\" or \"Responsible - Compl/Adj by Default\", _False_ otherwise\n",
    "* disposition_admission = _True_ if  'disposition' is \"Responsible by Admission\" , _False_ otherwise\n",
    "* disposition_determination = _True_ if  'disposition' is \"Responsible by Determination\" or \"Responsible - Compl/Adj by Determination\",  _False_ otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detriot_resident\n",
    "\n",
    "First fill \"NaN\" values with \"unknown\", then convert all the characters to lower case, and removes all punctuation. Finally use regular expressions to find all strings that start with \"det\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Creates 'detriot_resident' feature, setting all values to False\n",
    "blight_df['detriot_resident'] = 0\n",
    "# Fill all \"NaN\" with \"unknown\"\n",
    "blight_df['mailing_address_city'].fillna(value=\"unknown\", inplace=True)\n",
    "# Convert all characters to lower case\n",
    "blight_df.loc[:, 'mailing_address_city'] = blight_df['mailing_address_city'].str.lower()\n",
    "# Removes all punctuation\n",
    "blight_df.loc[:, 'mailing_address_city'] = blight_df['mailing_address_city'].str.extract('(^[a-z ]+)')\n",
    "# Refill all \"NaN\" with \"unknown\"\n",
    "blight_df['mailing_address_city'].fillna(value=\"unknown\", inplace=True)\n",
    "# Finds all strings that start with \"det\" and set \"detriot_resident\" to True for these values\n",
    "blight_df.loc[blight_df['mailing_address_city'].str.contains('(^det)'), 'detriot_resident'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### michigan_resident\n",
    "First fill \"NaN\" values with \"un\", then convert all the characters to lower case, and removes all punctuation. Finally use regular expressions to find all strings that start with \"mi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Creates 'michigan_resident' feature, setting all values to False\n",
    "blight_df['michigan_resident'] = 0\n",
    "# Fill all \"NaN\" with \"unknown\"\n",
    "blight_df['mailing_address_state'].fillna(value=\"un\", inplace=True)\n",
    "# Convert all characters to lower case\n",
    "blight_df.loc[:, 'mailing_address_state'] = blight_df['mailing_address_state'].str.lower()\n",
    "# Removes all punctuation\n",
    "blight_df.loc[:, 'mailing_address_state'] = blight_df['mailing_address_state'].str.extract('(^[a-z ]+)')\n",
    "# Refill all \"NaN\" with \"unknown\"\n",
    "blight_df['mailing_address_state'].fillna(value=\"un\", inplace=True)\n",
    "# Finds all strings that start with \"det\" and set \"detriot_resident\" to True for these values\n",
    "blight_df.loc[blight_df['mailing_address_state'].str.contains('(^mi)'), 'michigan_resident'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### us_resident\n",
    "First set to True for all observations that have a known state, then False for all observations that have a non-null value in country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the 'us_resident' feature\n",
    "blight_df['us_resident'] = 0 \n",
    "# Sets 'us_resident' to True if the 'mailing_address_state' is not unknown\n",
    "blight_df.loc[blight_df['mailing_address_state'] != 'un', 'us_resident'] = 1\n",
    "# Sets 'us_resident' to False if the 'mailing_address_country' is not unknown\n",
    "blight_df.loc[~blight_df['mailing_address_country'].isnull(), 'us_resident'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### violation_date\n",
    "Convert 'violation_date' to proper date format and extract the numeric month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'violation_date' to proper date format  \n",
    "blight_df['violation_date'] = pd.DatetimeIndex(blight_df['violation_date']).date\n",
    "# Extract the numeric month. Save this as 'violation_month'\n",
    "blight_df['violation_month'] = pd.DatetimeIndex(blight_df['violation_date']).month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### days_difference\n",
    "Convert 'hearing_date' to proper date format and subtract 'violation_date' from 'hearing_date'. Convert this difference to days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'hearing_date' to proper date format\n",
    "blight_df['hearing_date'] = pd.DatetimeIndex(blight_df['hearing_date']).date\n",
    "# Subtract 'violation_date' from 'hearing_date'. Convert this difference to days.\n",
    "blight_df['days_difference'] = (blight_df['hearing_date'] - blight_df['violation_date'])/np.timedelta64(1, 'D')\n",
    "# Remove observations where 'days_difference' is negative (This is dirty data)\n",
    "blight_df = blight_df.loc[(blight_df['days_difference'] > 0), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### disposition_fine_waived/disposition_default/disposition_admission/'disposition_determination'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "blight_df['disposition_fine_waived'] = 0\n",
    "blight_df['disposition_default'] = 0\n",
    "blight_df['disposition_admission'] = 0\n",
    "blight_df['disposition_determination'] = 0\n",
    "\n",
    "blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Determination', 'disposition_fine_waived'] = 1\n",
    "blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Admission', 'disposition_fine_waived'] = 1\n",
    "\n",
    "blight_df.loc[blight_df['disposition'] == 'Responsible by Default', 'disposition_default'] = 1\n",
    "blight_df.loc[blight_df['disposition'] == 'Responsible - Compl/Adj by Default', 'disposition_default'] = 1\n",
    "\n",
    "blight_df.loc[blight_df['disposition'] == 'Responsible by Admission', 'disposition_admission'] = 1\n",
    "\n",
    "blight_df.loc[blight_df['disposition'] == 'Responsible by Determination', 'disposition_determination'] = 1\n",
    "blight_df.loc[blight_df['disposition'] == 'Responsible - Compl/Adj by Determination', 'disposition_determination'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 250521 entries, 47056 to 359077\n",
      "Data columns (total 27 columns):\n",
      "agency_name                  250521 non-null object\n",
      "mailing_address_city         250521 non-null object\n",
      "mailing_address_state        250521 non-null object\n",
      "mailing_address_country      1644 non-null object\n",
      "violation_date               250521 non-null object\n",
      "hearing_date                 250521 non-null object\n",
      "hearing_time                 250520 non-null object\n",
      "violation_description        250520 non-null object\n",
      "disposition                  242469 non-null object\n",
      "fine_amount                  250520 non-null float64\n",
      "admin_fee                    250521 non-null float64\n",
      "state_fee                    250521 non-null float64\n",
      "late_fee                     250521 non-null float64\n",
      "discount_amount              250521 non-null float64\n",
      "judgment_amount              250521 non-null float64\n",
      "violation_latitude           250429 non-null float64\n",
      "violation_longitude          250429 non-null float64\n",
      "compliance                   250521 non-null float64\n",
      "detriot_resident             250521 non-null int64\n",
      "michigan_resident            250521 non-null int64\n",
      "us_resident                  250521 non-null int64\n",
      "violation_month              250521 non-null int64\n",
      "days_difference              250521 non-null float64\n",
      "disposition_fine_waived      250521 non-null int64\n",
      "disposition_default          250521 non-null int64\n",
      "disposition_admission        250521 non-null int64\n",
      "disposition_determination    250521 non-null int64\n",
      "dtypes: float64(10), int64(8), object(9)\n",
      "memory usage: 63.5+ MB\n"
     ]
    }
   ],
   "source": [
    "blight_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violation Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blight_df.dropna(axis=0, subset=['violation_description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "\n",
    "# Use CountVectorizor to find three letter tokens, remove stop_words, \n",
    "# remove tokens that don't appear in at least 20 documents,\n",
    "# remove tokens that appear in more than 20% of the documents\n",
    "vect = CountVectorizer(min_df=20, max_df=0.2, stop_words='english', token_pattern='(?u)\\\\b\\\\w\\\\w\\\\w+\\\\b')\n",
    "\n",
    "# Fit and transform\n",
    "X = vect.fit_transform(blight_df['violation_description'])\n",
    "\n",
    "# Convert sparse matrix to gensim corpus.\n",
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "\n",
    "# Mapping from word IDs to words (To be used in LdaModel's id2word parameter)\n",
    "id_map = dict((v, k) for k, v in vect.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the gensim.models.ldamodel.LdaModel constructor to estimate \n",
    "# LDA model parameters on the corpus, and save to the variable `ldamodel`\n",
    "\n",
    "# Your code here:\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, \n",
    "        id2word=id_map, passes=25, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.326*\"vehicle\" + 0.314*\"motor\" + 0.313*\"inoperable\" + 0.032*\"storage\" + 0.003*\"premise\"'),\n",
       " (1,\n",
       "  '0.468*\"rental\" + 0.388*\"registration\" + 0.012*\"residential\" + 0.011*\"defective\" + 0.011*\"vehicles\"'),\n",
       " (2,\n",
       "  '0.232*\"public\" + 0.229*\"free\" + 0.228*\"sidewalks\" + 0.228*\"adjoining\" + 0.041*\"hazardous\"'),\n",
       " (3,\n",
       "  '0.105*\"hours\" + 0.100*\"bulk\" + 0.100*\"time\" + 0.100*\"designated\" + 0.100*\"deposited\"'),\n",
       " (4,\n",
       "  '0.148*\"collection\" + 0.108*\"private\" + 0.084*\"containers\" + 0.081*\"secure\" + 0.077*\"city\"'),\n",
       " (5,\n",
       "  '0.083*\"comply\" + 0.074*\"unlawful\" + 0.069*\"order\" + 0.069*\"emergency\" + 0.068*\"danger\"'),\n",
       " (6,\n",
       "  '0.171*\"premises\" + 0.169*\"accumulate\" + 0.169*\"lie\" + 0.169*\"allowing\" + 0.169*\"bulk\"'),\n",
       " (7,\n",
       "  '0.086*\"vacant\" + 0.077*\"maintain\" + 0.070*\"structure\" + 0.055*\"requirements\" + 0.055*\"113\"'),\n",
       " (8,\n",
       "  '0.221*\"growth\" + 0.221*\"plant\" + 0.221*\"weeds\" + 0.221*\"excessive\" + 0.019*\"failed\"'),\n",
       " (9,\n",
       "  '0.068*\"containers\" + 0.066*\"early\" + 0.066*\"violation\" + 0.065*\"approved\" + 0.065*\"remain\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topics(num_topics=10, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_name</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>violator_name</th>\n",
       "      <th>violation_street_number</th>\n",
       "      <th>violation_street_name</th>\n",
       "      <th>mailing_address_street_name</th>\n",
       "      <th>mailing_address_street_name.1</th>\n",
       "      <th>mailing_address_city</th>\n",
       "      <th>mailing_address_state</th>\n",
       "      <th>mailing_address_zip_code</th>\n",
       "      <th>...</th>\n",
       "      <th>disposition</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>admin_fee</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>violation_latitude</th>\n",
       "      <th>violation_longitude</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329109</th>\n",
       "      <td>Department of Public Works</td>\n",
       "      <td>Maydell Bell</td>\n",
       "      <td>PHILLIP COLE</td>\n",
       "      <td>15707</td>\n",
       "      <td>PREST</td>\n",
       "      <td>GRANDMONT</td>\n",
       "      <td>GRANDMONT</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>MI</td>\n",
       "      <td>48227</td>\n",
       "      <td>...</td>\n",
       "      <td>Responsible by Default</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$20.00</td>\n",
       "      <td>$10.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.405392</td>\n",
       "      <td>-83.198039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          agency_name inspector_name violator_name  \\\n",
       "ticket_id                                                            \n",
       "329109     Department of Public Works   Maydell Bell  PHILLIP COLE   \n",
       "\n",
       "           violation_street_number violation_street_name  \\\n",
       "ticket_id                                                  \n",
       "329109                       15707      PREST              \n",
       "\n",
       "          mailing_address_street_name mailing_address_street_name.1  \\\n",
       "ticket_id                                                             \n",
       "329109                      GRANDMONT                     GRANDMONT   \n",
       "\n",
       "          mailing_address_city mailing_address_state mailing_address_zip_code  \\\n",
       "ticket_id                                                                       \n",
       "329109                 DETROIT                    MI                    48227   \n",
       "\n",
       "             ...                 disposition fine_amount admin_fee state_fee  \\\n",
       "ticket_id    ...                                                               \n",
       "329109       ...      Responsible by Default         NaN    $20.00    $10.00   \n",
       "\n",
       "          late_fee discount_amount judgment_amount violation_latitude  \\\n",
       "ticket_id                                                               \n",
       "329109       $0.00           $0.00            30.0          42.405392   \n",
       "\n",
       "          violation_longitude compliance  \n",
       "ticket_id                                 \n",
       "329109             -83.198039        0.0  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blight_df.loc[blight_df['violation_description'].isnull(), :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
