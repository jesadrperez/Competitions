{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Blight Violations\n",
    "\n",
    "_This project was completed as a part of the Applied Data Science with Python Specialization from Coursera._\n",
    "\n",
    "In this project, we will evaluate the performance and predictive power of a model that has been trained and tested on data collected from Blight Violation Notices (BVN), or Blight Tickets, that have been issued to property owners who have violated City of Detroit ordinances that govern how property owners must maintain the exterior of their property. Blight Tickets are issued by city inspectors, police officers, neighborhood city hall managers and other city officials who investigate complaints of blight and are managed by the Department of Administrative Hearings.\n",
    "\n",
    "The target variable is compliance, which is __True__ if the ticket was paid early, on time, or within one month of the hearing data, __False__ if the ticket was paid after the hearing date or not at all, and __Null__ if the violator was found not responsible. Compliance is not avaliable in the dataset so it must be calculated.\n",
    "\n",
    "The dataset for this project originates from the City of Detroit's Open Data Portal initiative and is updated daily. For this project the dataset spans tickets issued from March 2004 to March 2018. The dataset is avaliable at: https://data.detroitmi.gov/Property-Parcels/Blight-Violations/ti6p-wcg4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "Imports the raw data, calculates compliance for each ticket, removes features that cause data leakage, and seperates the data into two dataset based on when the violation occured. Violations issused before 2017 will be used to train and test the model, and tickets issued on and after 2017 will be used to validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "# To make the notebook's output stable across runs\n",
    "random_seed = 12062017\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_blight_raw(blight_path):\n",
    "    '''\n",
    "    Loads the raw blight_violations.csv\n",
    "    Returns a pandas dataframe.\n",
    "    '''\n",
    "    csv_path = os.path.join(blight_path, \"Blight_Violations.csv\")\n",
    "    blight_raw = pd.read_csv(csv_path, encoding='ISO-8859-1')\n",
    "    print(\"RAW Blight Violations dataset has {} observations with {} features each.\".format(*blight_raw.shape))\n",
    "    return blight_raw\n",
    "\n",
    "def pre_processing(blight_df):\n",
    "    ''' \n",
    "    Takes blight panda dataframe and makes column names more reabable, sets ticket_id as index, creates compliance (the \n",
    "    prediction variable), and creates compliance_details (explains why a tickets was labeled as complantent or non-complantent).\n",
    "    Returns a panda dataframe.\n",
    "    '''\n",
    "    # Makes column names more reabable\n",
    "    # Gets columns from dataframe\n",
    "    columns_names = pd.Series(blight_df.columns)\n",
    "    # Removes parentheses, removes right spaces\n",
    "    columns_names = columns_names.str.split('(').str[0].str.strip()\n",
    "    # Coverts column names to lowercase and replaces spaces with underscores\n",
    "    columns_names = columns_names.str.lower().str.replace(' ', '_')\n",
    "    blight_df.columns = columns_names\n",
    "    # Sets ticket_id as index\n",
    "    blight_df.set_index('ticket_id', inplace=True)\n",
    "    # Defines prediction variable compliance and helper variable compliance_detail\n",
    "    # The values of these variables are NOT correct\n",
    "    blight_df['compliance'] = 0\n",
    "    blight_df['compliance_detail'] = np.NaN    \n",
    "    return blight_df\n",
    "\n",
    "def clean_up(blight_df):\n",
    "    # Removes instances where 'ticket_issued_date' is not in (2000, 2017) \n",
    "    blight_df = blight_df[blight_df['violation_date'].str.contains('[0-9]{2}/[0-9]{2}/[20]{2}[0-9]{2}') == True]\n",
    "    # Converts 'ticket_issued_date' to datetime\n",
    "    blight_df.loc[:, 'violation_date'] = pd.to_datetime(blight_df['violation_date'])\n",
    "    # Converts 'payment_date' to datetime\n",
    "    blight_df.loc[:, 'payment_date'] = pd.to_datetime(blight_df['payment_date'].str.extract('([0-9]{2}/[0-9]{2}/20{1}[0-9]{2})')) \n",
    "    # Converts bad values in 'ticket_issued_time' to NaNs (Dataset error removed by publisher)\n",
    "    #blight_df.loc[blight_df['violation_date'] == '00000000000000.000', 'violation_date'] = np.nan\n",
    "    # Converts 'ticket_issued_time' to datetime.time\n",
    "    blight_df.loc[:, 'ticket_issued_time'] = pd.DatetimeIndex(blight_df['ticket_issued_time']).time\n",
    "    # Converts 'hearing_time' to datetime.time\n",
    "    blight_df.loc[:, 'hearing_time'] = pd.DatetimeIndex(blight_df['hearing_time']).time\n",
    "    # Remove \"$\" from 'judgement_amount'\n",
    "    blight_df.loc[:, 'judgment_amount'] = blight_df['judgment_amount'].str.strip('$')    \n",
    "    # Converts 'judgment_amount' to float    \n",
    "    blight_df.loc[:, 'judgment_amount'] = blight_df['judgment_amount'].astype(float)\n",
    "    # Removes \"$\" from 'payment_amount' and converts it to float\n",
    "    blight_df.loc[:, 'payment_amount'] = blight_df['payment_amount'].str.strip('$').astype(float)\n",
    "    return blight_df\n",
    "\n",
    "def null_compliance(blight_df):\n",
    "    '''\n",
    "    Compliance = np.NaN\n",
    "    Tickets that cannot be classified as compliant or non-compliant because they were ruled as not responsible in disposition\n",
    "    or they are awaiting judgement.\n",
    "    Returns a pandas dataframe\n",
    "    '''\n",
    "    # Dispositions that are ruled as not responsible or are still pending\n",
    "    null_dispositions = ['Not responsible by Dismissal', 'Not responsible by City Dismissal', 'PENDING JUDGMENT', \n",
    "                 'Not responsible by Determination','SET-ASIDE (PENDING JUDGMENT)']\n",
    "    # Loops over dispositions and sets 'compliance' values to np.NaN\n",
    "    # Loops over dispositions and sets 'compliance_detail' values to 'Not Responsible/Pending Judgement'\n",
    "    for dispositions in null_dispositions:\n",
    "        blight_df.loc[blight_df['disposition'] == dispositions, 'compliance'] = np.NaN\n",
    "        blight_df.loc[blight_df['disposition'] == dispositions, 'compliance_detail'] = 'Not Responsible/Pending Judgement'\n",
    "    return blight_df\n",
    "\n",
    "def compliant(blight_df):\n",
    "    '''\n",
    "    Compliance = 1\n",
    "    Tickets that are classified as compliant because they had no fine, fine was waved, made a payment with hearing pending,\n",
    "    early payment (hearing not pending), payment on time, or payment within one month after hearing date.\n",
    "    Returns a pandas dataframe\n",
    "    '''\n",
    "    ## Compliant by no fine\n",
    "    # Fine Waived by Determintation\n",
    "    blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Determination', 'compliance'] = 1\n",
    "    blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Determination', 'compliance_detail'] = 'Compliant by no fine'\n",
    "    # Fine Waived by Admission\n",
    "    blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Admission', 'compliance'] = 1\n",
    "    blight_df.loc[blight_df['disposition'] == 'Responsible (Fine Waived) by Admission', 'compliance_detail'] = 'Compliant by no fine'\n",
    "    ## Compliant by Payment\n",
    "    # Payment with PENDING hearing\n",
    "    blight_df.loc[(\n",
    "        (blight_df['hearing_date'] == 'PENDING') &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance'] = 1\n",
    "    blight_df.loc[(\n",
    "        (blight_df['hearing_date'] == 'PENDING') &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Compliant by payment with PENDING hearing'\n",
    "    # Transforms values in 'hearing_date' and 'payment_date' to panda date types\n",
    "    dummy_hearing_date = blight_df['hearing_date'].copy()\n",
    "    blight_df.loc[blight_df['hearing_date'] == 'PENDING', 'hearing_date'] = np.nan\n",
    "    blight_df.loc[:, 'hearing_date'] = pd.to_datetime(blight_df['hearing_date'].str.extract('([0-9]{2}/[0-9]{2}/20{1}[0-9]{2})'))\n",
    "    # Early Payment, payment before hearing date\n",
    "    blight_df.loc[(\n",
    "        (blight_df['payment_date'] < blight_df['hearing_date']) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance'] = 1\n",
    "    blight_df.loc[(\n",
    "        (blight_df['payment_date'] < blight_df['hearing_date']) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Compliant by early payment'\n",
    "    # Payment on time, payment on hearing date\n",
    "    blight_df.loc[(\n",
    "        (blight_df['payment_date'] == blight_df['hearing_date']) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance'] = 1\n",
    "    blight_df.loc[(\n",
    "        (blight_df['payment_date'] == blight_df['hearing_date']) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Compliant by payment on time'\n",
    "    # Payment within one month after hearing date\n",
    "    blight_df.loc[(\n",
    "        ((blight_df['payment_date'] - blight_df['hearing_date'])/np.timedelta64(1, 'M') <= 1.0) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance'] = 1\n",
    "    blight_df.loc[(\n",
    "        ((blight_df['payment_date'] - blight_df['hearing_date'])/np.timedelta64(1, 'M') <= 1.0) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Compliant by payment within 1 Month'\n",
    "    # Sets 'hearing_date' to orginal state\n",
    "    blight_df.loc[:, 'hearing_date'] = dummy_hearing_date\n",
    "    return blight_df\n",
    "\n",
    "def non_compliant(blight_df):\n",
    "    '''\n",
    "    Compliance = 0\n",
    "    Tickets that are classified as non-compliant because they made no payment or a payment after one month (late payment).\n",
    "    Returns a pandas dataframe\n",
    "    '''\n",
    "    # Transforms values in 'hearing_date' to panda date types\n",
    "    dummy_hearing_date = blight_df['hearing_date'].copy()\n",
    "    blight_df.loc[blight_df['hearing_date'] == 'PENDING', 'hearing_date'] = np.nan\n",
    "    blight_df.loc[:, 'hearing_date'] = pd.to_datetime(blight_df['hearing_date'].str.extract('([0-9]{2}/[0-9]{2}/20{1}[0-9]{2})'))\n",
    "    # Non-compliant by late payment\n",
    "    blight_df.loc[(\n",
    "        ((blight_df['payment_date'] - blight_df['hearing_date'])/np.timedelta64(1, 'M') > 1.0) &\n",
    "        (blight_df['payment_amount'] > 0) &\n",
    "        (blight_df['compliance_detail'].isnull())), 'compliance_detail'] = 'Non-compliant by late payment more than 1 month'\n",
    "    # Non-compliant by no payment\n",
    "    blight_df.loc[blight_df['compliance_detail'].isnull(), 'compliance_detail'] = 'Non-compliant by no payment'\n",
    "    # Sets 'hearing_date' to orginal state\n",
    "    blight_df.loc[:, 'hearing_date'] = dummy_hearing_date\n",
    "    return blight_df\n",
    "\n",
    "def populate_compliance(blight_df):\n",
    "    '''\n",
    "    Populates compliance and compliance_details in blight_df with the correct values. \n",
    "    Returns a panda dataframe.\n",
    "    '''\n",
    "    blight_df = null_compliance(blight_df)\n",
    "    blight_df = compliant(blight_df)\n",
    "    blight_df = non_compliant(blight_df)  \n",
    "    return blight_df\n",
    "\n",
    "def remove_leakage(blight_df):\n",
    "    ''' \n",
    "    In blight_df removes variables to prevent data leakage and variables with mostly NaNs,\n",
    "    Returns a panda dataframe\n",
    "    '''\n",
    "    blight_df = blight_df[['agency_name', 'inspector_name', 'violator_name','violation_street_number', 'violation_street_name', \n",
    "                       'mailing_address_street_name', 'mailing_address_street_name', 'mailing_address_city', \n",
    "                       'mailing_address_state', 'mailing_address_zip_code', 'mailing_address_non-usa_code', \n",
    "                       'mailing_address_country', 'violation_date', 'hearing_date', 'violation_code', 'violation_description',\n",
    "                       'disposition', 'fine_amount', 'admin_fee', 'state_fee', 'late_fee', 'discount_amount', \n",
    "                       'judgment_amount', 'violation_latitude', 'violation_longitude', 'compliance']]  \n",
    "    return blight_df \n",
    "\n",
    "def process_blight(blight_path, pre_process):\n",
    "    '''\n",
    "    If pre_process is true - Loads the raw blight_violations.csv, cleans the data, computes compliance, removes features with \n",
    "    data leakage and saves this dataframe. If pre_process is False, then it loads the pre-processed data.\n",
    "    Returns a pandas dataframe.\n",
    "    '''\n",
    "    if pre_process == False:\n",
    "        blight_df = load_blight_raw(blight_path)\n",
    "        blight_df = pre_processing(blight_df)\n",
    "        blight_df = clean_up(blight_df)\n",
    "        blight_df = populate_compliance(blight_df)\n",
    "        blight_df = remove_leakage(blight_df)\n",
    "        save_blight_data(blight_path, blight_df)\n",
    "    else:\n",
    "        blight_df = load_blight(blight_path)\n",
    "    print(\"PROCESSED Blight Violations dataset has {} observations with {} features each.\".format(*blight_df.shape))        \n",
    "    return blight_df\n",
    "\n",
    "def save_blight_data(blight_path, blight_df):\n",
    "    '''\n",
    "    Saves the processed blight_df\n",
    "    Returns nothing.\n",
    "    '''\n",
    "    csv_path = os.path.join(blight_path, \"Blight_Violations_Processed.csv\")\n",
    "    blight_df.to_csv(csv_path)\n",
    "    \n",
    "def load_blight(blight_path):\n",
    "    '''\n",
    "    Loads the preprocessed blight_violations.csv\n",
    "    Returns a pandas dataframe.\n",
    "    '''\n",
    "    csv_path = os.path.join(blight_path, \"Blight_Violations_Processed.csv\")\n",
    "    blight_df = pd.read_csv(csv_path)\n",
    "    blight_df.set_index('ticket_id', inplace=True)\n",
    "    return blight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSED Blight Violations dataset has 373844 observations with 26 features each.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 373844 entries, 47056 to 247933\n",
      "Data columns (total 26 columns):\n",
      "agency_name                      373844 non-null object\n",
      "inspector_name                   373844 non-null object\n",
      "violator_name                    373842 non-null object\n",
      "violation_street_number          373844 non-null int64\n",
      "violation_street_name            373779 non-null object\n",
      "mailing_address_street_name      373841 non-null object\n",
      "mailing_address_street_name.1    373841 non-null object\n",
      "mailing_address_city             372028 non-null object\n",
      "mailing_address_state            371565 non-null object\n",
      "mailing_address_zip_code         372025 non-null object\n",
      "mailing_address_non-usa_code     1819 non-null object\n",
      "mailing_address_country          1830 non-null object\n",
      "violation_date                   373844 non-null object\n",
      "hearing_date                     373234 non-null object\n",
      "violation_code                   373843 non-null object\n",
      "violation_description            373843 non-null object\n",
      "disposition                      365161 non-null object\n",
      "fine_amount                      373842 non-null object\n",
      "admin_fee                        373844 non-null object\n",
      "state_fee                        373844 non-null object\n",
      "late_fee                         373844 non-null object\n",
      "discount_amount                  373844 non-null object\n",
      "judgment_amount                  373844 non-null float64\n",
      "violation_latitude               373719 non-null float64\n",
      "violation_longitude              373719 non-null float64\n",
      "compliance                       251545 non-null float64\n",
      "dtypes: float64(4), int64(1), object(21)\n",
      "memory usage: 77.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loads the raw blight data and pre-processes\n",
    "#blight_df = process_blight(r\"C:\\Users\\Adrian\\Google Drive\\Datasets\\Blight-Violations\", True)\n",
    "blight_df = process_blight(r\"C:\\Users\\aperez\\Google Drive\\Datasets\\Blight-Violations\", True)\n",
    "# Checks to make sure the data loaded properly\n",
    "blight_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets remove unrelevant fields and useless observations -\n",
    "* Observations where compliance is _NaNs_, these observations provide no use to me\n",
    "* Features that are too noisey or contain many _NaNs_: inspector_name, violator_name, violation_street_number, violation_street_name, mailing_address_street_name, mailing_address_street_name.1, violation_code, and violation_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 251545 entries, 47056 to 359077\n",
      "Data columns (total 17 columns):\n",
      "agency_name                251545 non-null object\n",
      "mailing_address_city       249910 non-null object\n",
      "mailing_address_state      249495 non-null object\n",
      "mailing_address_country    1646 non-null object\n",
      "violation_date             251545 non-null object\n",
      "hearing_date               250935 non-null object\n",
      "violation_description      251544 non-null object\n",
      "disposition                242862 non-null object\n",
      "fine_amount                251544 non-null object\n",
      "admin_fee                  251545 non-null object\n",
      "state_fee                  251545 non-null object\n",
      "late_fee                   251545 non-null object\n",
      "discount_amount            251545 non-null object\n",
      "judgment_amount            251545 non-null float64\n",
      "violation_latitude         251451 non-null float64\n",
      "violation_longitude        251451 non-null float64\n",
      "compliance                 251545 non-null float64\n",
      "dtypes: float64(4), object(13)\n",
      "memory usage: 44.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop observations where compliance is NaNs\n",
    "blight_df.dropna(axis=0, subset=['compliance'], inplace=True)\n",
    "# Drop useless features\n",
    "blight_df.drop(axis=1, columns=['inspector_name', 'violator_name',\n",
    "       'violation_street_number', 'violation_street_name',\n",
    "       'mailing_address_street_name', 'mailing_address_street_name.1', 'mailing_address_zip_code', 'mailing_address_non-usa_code',\n",
    "        'violation_code'], inplace=True)\n",
    "blight_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering \n",
    "\n",
    "Now, we will construct new features. These are:\n",
    "* detriot_resident - _True_ if 'mailing_address_city' is Detriot, _False_ otherwise\n",
    "* michigan_resident - _True_ if 'mailing_address_state' is Michigan, _False_ otherwise\n",
    "* us_resident - _True_ if 'mailing_address_state' is not null but _False_ if 'mailing_address_country' is not null, _False_ otherwise\n",
    "* violation_month = the numeric month (1-12) that violation occured on\n",
    "* days_difference = the number of days between when the violation occured and when the hearing date is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detriot_resident\n",
    "\n",
    "First fill \"NaN\" values with \"unknown\", then convert all the characters to lower case, and removes all punctuation. Finally use regular expressions to find all strings that start with \"det\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates 'detriot_resident' feature, setting all values to False\n",
    "blight_df['detriot_resident'] = 0\n",
    "# Fill all \"NaN\" with \"unknown\"\n",
    "blight_df['mailing_address_city'].fillna(value=\"unknown\", inplace=True)\n",
    "# Convert all characters to lower case\n",
    "blight_df.loc[:, 'mailing_address_city'] = blight_df['mailing_address_city'].str.lower()\n",
    "# Removes all punctuation\n",
    "blight_df.loc[:, 'mailing_address_city'] = blight_df['mailing_address_city'].str.extract('(^[a-z ]+)')\n",
    "# Refill all \"NaN\" with \"unknown\"\n",
    "blight_df['mailing_address_city'].fillna(value=\"unknown\", inplace=True)\n",
    "# Finds all strings that start with \"det\" and set \"detriot_resident\" to True for these values\n",
    "blight_df.loc[blight_df['mailing_address_city'].str.contains('(^det)'), 'detriot_resident'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### michigan_resident\n",
    "First fill \"NaN\" values with \"un\", then convert all the characters to lower case, and removes all punctuation. Finally use regular expressions to find all strings that start with \"mi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aperez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \n",
      "C:\\Users\\aperez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Creates 'michigan_resident' feature, setting all values to False\n",
    "blight_df['michigan_resident'] = 0\n",
    "# Fill all \"NaN\" with \"unknown\"\n",
    "blight_df['mailing_address_state'].fillna(value=\"un\", inplace=True)\n",
    "# Convert all characters to lower case\n",
    "blight_df.loc[:, 'mailing_address_state'] = blight_df['mailing_address_state'].str.lower()\n",
    "# Removes all punctuation\n",
    "blight_df.loc[:, 'mailing_address_state'] = blight_df['mailing_address_state'].str.extract('(^[a-z ]+)')\n",
    "# Refill all \"NaN\" with \"unknown\"\n",
    "blight_df['mailing_address_state'].fillna(value=\"un\", inplace=True)\n",
    "# Finds all strings that start with \"det\" and set \"detriot_resident\" to True for these values\n",
    "blight_df.loc[blight_df['mailing_address_state'].str.contains('(^mi)'), 'michigan_resident'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### us_resident\n",
    "First set to True for all observations that have a known state, then False for all observations that have a non-null value in country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the 'us_resident' feature\n",
    "blight_df['us_resident'] = 0 \n",
    "# Sets 'us_resident' to True if the 'mailing_address_state' is not unknown\n",
    "blight_df.loc[blight_df['mailing_address_state'] != 'un', 'us_resident'] = 1\n",
    "# Sets 'us_resident' to False if the 'mailing_address_country' is not unknown\n",
    "blight_df.loc[~blight_df['mailing_address_country'].isnull(), 'us_resident'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### violation_date\n",
    "Convert 'violation_date' to proper date format and extract the numeric month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'violation_date' to proper date format  \n",
    "blight_df['violation_date'] = pd.DatetimeIndex(blight_df['violation_date']).date\n",
    "# Extract the numeric month. Save this as 'violation_month'\n",
    "blight_df['violation_month'] = pd.DatetimeIndex(blight_df['violation_date']).month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### days_difference\n",
    "Convert 'hearing_date' to proper date format and subtract 'violation_date' from 'hearing_date'. Convert this difference to days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'hearing_date' to proper date format\n",
    "blight_df['hearing_date'] = pd.DatetimeIndex(blight_df['hearing_date']).date\n",
    "# Subtract 'violation_date' from 'hearing_date'. Convert this difference to days.\n",
    "blight_df['days_difference'] = (blight_df['hearing_date'] - blight_df['violation_date'])/np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_date</th>\n",
       "      <th>hearing_date</th>\n",
       "      <th>days_difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239383</th>\n",
       "      <td>2010-12-08</td>\n",
       "      <td>2010-05-13</td>\n",
       "      <td>-209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355322</th>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299434</th>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239317</th>\n",
       "      <td>2010-12-21</td>\n",
       "      <td>2010-06-14</td>\n",
       "      <td>-190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239243</th>\n",
       "      <td>2010-12-21</td>\n",
       "      <td>2010-03-22</td>\n",
       "      <td>-274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268084</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>2011-03-17</td>\n",
       "      <td>-280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357209</th>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300023</th>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>-307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299321</th>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>-328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355682</th>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359015</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357208</th>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353175</th>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353174</th>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356337</th>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355681</th>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357210</th>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356336</th>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355323</th>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353173</th>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355190</th>\n",
       "      <td>2016-03-11</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310773</th>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>2014-02-12</td>\n",
       "      <td>-302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239379</th>\n",
       "      <td>2010-12-07</td>\n",
       "      <td>2010-05-13</td>\n",
       "      <td>-208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267970</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>2011-03-03</td>\n",
       "      <td>-294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239378</th>\n",
       "      <td>2010-12-07</td>\n",
       "      <td>2010-05-13</td>\n",
       "      <td>-208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299440</th>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239323</th>\n",
       "      <td>2010-12-22</td>\n",
       "      <td>2010-06-14</td>\n",
       "      <td>-191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239321</th>\n",
       "      <td>2010-12-21</td>\n",
       "      <td>2010-06-14</td>\n",
       "      <td>-190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239316</th>\n",
       "      <td>2010-12-21</td>\n",
       "      <td>2010-06-14</td>\n",
       "      <td>-190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267985</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>2011-03-17</td>\n",
       "      <td>-280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239319</th>\n",
       "      <td>2010-12-21</td>\n",
       "      <td>2010-06-14</td>\n",
       "      <td>-190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239330</th>\n",
       "      <td>2010-12-22</td>\n",
       "      <td>2010-04-19</td>\n",
       "      <td>-247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284946</th>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>2012-01-25</td>\n",
       "      <td>-317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267964</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>2011-05-12</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284943</th>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>2012-01-25</td>\n",
       "      <td>-310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357746</th>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>-152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299467</th>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>2013-01-24</td>\n",
       "      <td>-321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267968</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>2011-03-03</td>\n",
       "      <td>-294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285294</th>\n",
       "      <td>2012-12-20</td>\n",
       "      <td>2012-02-08</td>\n",
       "      <td>-316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299318</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299315</th>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>-336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239255</th>\n",
       "      <td>2010-12-23</td>\n",
       "      <td>2010-01-21</td>\n",
       "      <td>-336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299314</th>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>-329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239244</th>\n",
       "      <td>2010-12-21</td>\n",
       "      <td>2010-04-05</td>\n",
       "      <td>-260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239245</th>\n",
       "      <td>2010-12-21</td>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>-330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299308</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284948</th>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>2012-01-25</td>\n",
       "      <td>-317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299306</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299307</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299316</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>-323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310453</th>\n",
       "      <td>2014-12-05</td>\n",
       "      <td>2014-01-22</td>\n",
       "      <td>-317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299312</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299328</th>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267054</th>\n",
       "      <td>2011-12-16</td>\n",
       "      <td>2011-03-10</td>\n",
       "      <td>-281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310880</th>\n",
       "      <td>2014-12-19</td>\n",
       "      <td>2014-02-20</td>\n",
       "      <td>-302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267052</th>\n",
       "      <td>2011-12-16</td>\n",
       "      <td>2011-03-10</td>\n",
       "      <td>-281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239327</th>\n",
       "      <td>2010-12-22</td>\n",
       "      <td>2010-06-14</td>\n",
       "      <td>-191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299313</th>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>-329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299319</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299309</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>2013-01-30</td>\n",
       "      <td>-316.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          violation_date hearing_date  days_difference\n",
       "ticket_id                                             \n",
       "239383        2010-12-08   2010-05-13           -209.0\n",
       "355322        2016-03-17   2015-11-13           -125.0\n",
       "299434        2013-12-11   2013-01-30           -315.0\n",
       "239317        2010-12-21   2010-06-14           -190.0\n",
       "239243        2010-12-21   2010-03-22           -274.0\n",
       "268084        2011-12-22   2011-03-17           -280.0\n",
       "357209        2016-04-07   2015-11-13           -146.0\n",
       "300023        2013-12-19   2013-02-15           -307.0\n",
       "299321        2013-12-19   2013-01-25           -328.0\n",
       "355682        2016-03-22   2015-11-13           -130.0\n",
       "359015        2016-04-28   2015-11-13           -167.0\n",
       "357208        2016-04-07   2015-11-13           -146.0\n",
       "353175        2016-02-23   2015-11-13           -102.0\n",
       "353174        2016-02-23   2015-11-13           -102.0\n",
       "356337        2016-03-29   2015-11-13           -137.0\n",
       "355681        2016-03-22   2015-11-13           -130.0\n",
       "357210        2016-04-07   2015-11-13           -146.0\n",
       "356336        2016-03-29   2015-11-13           -137.0\n",
       "355323        2016-03-17   2015-11-13           -125.0\n",
       "353173        2016-02-23   2015-11-13           -102.0\n",
       "355190        2016-03-11   2015-11-13           -119.0\n",
       "310773        2014-12-11   2014-02-12           -302.0\n",
       "239379        2010-12-07   2010-05-13           -208.0\n",
       "267970        2011-12-22   2011-03-03           -294.0\n",
       "239378        2010-12-07   2010-05-13           -208.0\n",
       "299440        2013-12-11   2013-01-30           -315.0\n",
       "239323        2010-12-22   2010-06-14           -191.0\n",
       "239321        2010-12-21   2010-06-14           -190.0\n",
       "239316        2010-12-21   2010-06-14           -190.0\n",
       "267985        2011-12-22   2011-03-17           -280.0\n",
       "...                  ...          ...              ...\n",
       "239319        2010-12-21   2010-06-14           -190.0\n",
       "239330        2010-12-22   2010-04-19           -247.0\n",
       "284946        2012-12-07   2012-01-25           -317.0\n",
       "267964        2011-12-22   2011-05-12           -224.0\n",
       "284943        2012-11-30   2012-01-25           -310.0\n",
       "357746        2016-04-13   2015-11-13           -152.0\n",
       "299467        2013-12-11   2013-01-24           -321.0\n",
       "267968        2011-12-22   2011-03-03           -294.0\n",
       "285294        2012-12-20   2012-02-08           -316.0\n",
       "299318        2013-12-12   2013-01-30           -316.0\n",
       "299315        2013-12-20   2013-01-18           -336.0\n",
       "239255        2010-12-23   2010-01-21           -336.0\n",
       "299314        2013-12-20   2013-01-25           -329.0\n",
       "239244        2010-12-21   2010-04-05           -260.0\n",
       "239245        2010-12-21   2010-01-25           -330.0\n",
       "299308        2013-12-12   2013-01-30           -316.0\n",
       "284948        2012-12-07   2012-01-25           -317.0\n",
       "299306        2013-12-12   2013-01-30           -316.0\n",
       "299307        2013-12-12   2013-01-30           -316.0\n",
       "299316        2013-12-12   2013-01-23           -323.0\n",
       "310453        2014-12-05   2014-01-22           -317.0\n",
       "299312        2013-12-12   2013-01-30           -316.0\n",
       "299328        2013-12-19   2013-01-30           -323.0\n",
       "267054        2011-12-16   2011-03-10           -281.0\n",
       "310880        2014-12-19   2014-02-20           -302.0\n",
       "267052        2011-12-16   2011-03-10           -281.0\n",
       "239327        2010-12-22   2010-06-14           -191.0\n",
       "299313        2013-12-20   2013-01-25           -329.0\n",
       "299319        2013-12-12   2013-01-30           -316.0\n",
       "299309        2013-12-12   2013-01-30           -316.0\n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blight_df.loc[blight_df['days_difference'] < -100, ['violation_date', 'hearing_date', 'days_difference']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violation Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blight_df.dropna(axis=0, subset=['violation_description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "\n",
    "# Use CountVectorizor to find three letter tokens, remove stop_words, \n",
    "# remove tokens that don't appear in at least 20 documents,\n",
    "# remove tokens that appear in more than 20% of the documents\n",
    "vect = CountVectorizer(min_df=20, max_df=0.2, stop_words='english', token_pattern='(?u)\\\\b\\\\w\\\\w\\\\w+\\\\b')\n",
    "\n",
    "# Fit and transform\n",
    "X = vect.fit_transform(blight_df['violation_description'])\n",
    "\n",
    "# Convert sparse matrix to gensim corpus.\n",
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "\n",
    "# Mapping from word IDs to words (To be used in LdaModel's id2word parameter)\n",
    "id_map = dict((v, k) for k, v in vect.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the gensim.models.ldamodel.LdaModel constructor to estimate \n",
    "# LDA model parameters on the corpus, and save to the variable `ldamodel`\n",
    "\n",
    "# Your code here:\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, \n",
    "        id2word=id_map, passes=25, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.326*\"vehicle\" + 0.314*\"motor\" + 0.313*\"inoperable\" + 0.032*\"storage\" + 0.003*\"premise\"'),\n",
       " (1,\n",
       "  '0.468*\"rental\" + 0.388*\"registration\" + 0.012*\"residential\" + 0.011*\"defective\" + 0.011*\"vehicles\"'),\n",
       " (2,\n",
       "  '0.232*\"public\" + 0.229*\"free\" + 0.228*\"sidewalks\" + 0.228*\"adjoining\" + 0.041*\"hazardous\"'),\n",
       " (3,\n",
       "  '0.105*\"hours\" + 0.100*\"bulk\" + 0.100*\"time\" + 0.100*\"designated\" + 0.100*\"deposited\"'),\n",
       " (4,\n",
       "  '0.148*\"collection\" + 0.108*\"private\" + 0.084*\"containers\" + 0.081*\"secure\" + 0.077*\"city\"'),\n",
       " (5,\n",
       "  '0.083*\"comply\" + 0.074*\"unlawful\" + 0.069*\"order\" + 0.069*\"emergency\" + 0.068*\"danger\"'),\n",
       " (6,\n",
       "  '0.171*\"premises\" + 0.169*\"accumulate\" + 0.169*\"lie\" + 0.169*\"allowing\" + 0.169*\"bulk\"'),\n",
       " (7,\n",
       "  '0.086*\"vacant\" + 0.077*\"maintain\" + 0.070*\"structure\" + 0.055*\"requirements\" + 0.055*\"113\"'),\n",
       " (8,\n",
       "  '0.221*\"growth\" + 0.221*\"plant\" + 0.221*\"weeds\" + 0.221*\"excessive\" + 0.019*\"failed\"'),\n",
       " (9,\n",
       "  '0.068*\"containers\" + 0.066*\"early\" + 0.066*\"violation\" + 0.065*\"approved\" + 0.065*\"remain\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topics(num_topics=10, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_name</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>violator_name</th>\n",
       "      <th>violation_street_number</th>\n",
       "      <th>violation_street_name</th>\n",
       "      <th>mailing_address_street_name</th>\n",
       "      <th>mailing_address_street_name.1</th>\n",
       "      <th>mailing_address_city</th>\n",
       "      <th>mailing_address_state</th>\n",
       "      <th>mailing_address_zip_code</th>\n",
       "      <th>...</th>\n",
       "      <th>disposition</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>admin_fee</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>violation_latitude</th>\n",
       "      <th>violation_longitude</th>\n",
       "      <th>compliance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>329109</th>\n",
       "      <td>Department of Public Works</td>\n",
       "      <td>Maydell Bell</td>\n",
       "      <td>PHILLIP COLE</td>\n",
       "      <td>15707</td>\n",
       "      <td>PREST</td>\n",
       "      <td>GRANDMONT</td>\n",
       "      <td>GRANDMONT</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>MI</td>\n",
       "      <td>48227</td>\n",
       "      <td>...</td>\n",
       "      <td>Responsible by Default</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$20.00</td>\n",
       "      <td>$10.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.405392</td>\n",
       "      <td>-83.198039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          agency_name inspector_name violator_name  \\\n",
       "ticket_id                                                            \n",
       "329109     Department of Public Works   Maydell Bell  PHILLIP COLE   \n",
       "\n",
       "           violation_street_number violation_street_name  \\\n",
       "ticket_id                                                  \n",
       "329109                       15707      PREST              \n",
       "\n",
       "          mailing_address_street_name mailing_address_street_name.1  \\\n",
       "ticket_id                                                             \n",
       "329109                      GRANDMONT                     GRANDMONT   \n",
       "\n",
       "          mailing_address_city mailing_address_state mailing_address_zip_code  \\\n",
       "ticket_id                                                                       \n",
       "329109                 DETROIT                    MI                    48227   \n",
       "\n",
       "             ...                 disposition fine_amount admin_fee state_fee  \\\n",
       "ticket_id    ...                                                               \n",
       "329109       ...      Responsible by Default         NaN    $20.00    $10.00   \n",
       "\n",
       "          late_fee discount_amount judgment_amount violation_latitude  \\\n",
       "ticket_id                                                               \n",
       "329109       $0.00           $0.00            30.0          42.405392   \n",
       "\n",
       "          violation_longitude compliance  \n",
       "ticket_id                                 \n",
       "329109             -83.198039        0.0  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blight_df.loc[blight_df['violation_description'].isnull(), :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
